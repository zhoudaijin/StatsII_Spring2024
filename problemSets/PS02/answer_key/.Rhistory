stata("Dropbox/Trinity/projects/FrenchCCProject/drafts/CompLawRevisionPlan/COMPLAW2020PAPER/archive/2020draftandanalysis/my_dofile.do")
?stata
stata("Dropbox/Trinity/projects/FrenchCCProject/drafts/CompLawRevisionPlan/COMPLAW2020PAPER/archive/2020draftandanalysis/my_dofile.do", stata.version=14)
%    349+1+20
%    75+4+0
%    175+2+84
%    341+3+20
%    651+11+15
%    293+8+0
%    613+5+232
%    724+5+149
%    280+1+0
349+1+20
75+4+0
175+2+84
341+3+20
651+11+15
293+8+0
613+5+232
724+5+149
280+1+0
370 +
79+
261 +
364+
677+
301+
850+
878+
281
192+1+23
+
75+4+0 +
175+2+84 +
341+3+20 +
651+11+15 +
296+8+0+
613+5+232+
724+5+149+
280+1+0
370 +
79+
261 +
364+
677+
301+
850+
878+
281
349+1+20
75+4+0
175+2+84
341+3+20
651+11+15
293+8+0
613+5+232
724+5+149
280+1+0
349+1+20+
75+4+0 +
175+2+84+
341+3+20 +
651+11+15+
293+8+0 +
613+5+232+
724+5+149 +
280+1+0
370 +
79+
261 +
364+
677+
301+
850+
878+
281
192+1+23
192+1+23 +
75+4+0 +
175+2+84 +
341+3+20 +
651+11+15 +
296+8+0+
613+5+232+
724+5+149+
280+1+0
308+1+20
308+1+20+43+4+0 +
175+2+84
308+1+20+
43+4+0 +
175+2+84 +
341+3+20 +
651+11+15+
296+8+46 +
613+5+160+
757+5+140+280+1+0
set . seed (123)
data <− data.frame(x = runif(200, 1, 10)) data$y <− 0 + 2.75∗data$x + rnorm(200, 0, 1.5)
set.seed(123)
data <-data.frame(x = runif(200, 1, 100))
data$y <- 0 + 2.75*data$x +rnorm(200, 0, 1.5)
# write the function of the OLS regression with θ=(β, σ)
linear.lik <- function(theta, y, x){
n <- nrow(x)
k <- ncol(x)
beta <- theta[1:k]
sigma2 <- theta[k+1]^2
e <- y-x%*%beta
logl <- -0.5*n*log(2*pi)-0.5*n*log(sigma2)-((t(e)%*%e)/(2*sigma2))
return(-logl)
}
linear.MLE <- optim(fn=linear.lik, par = c(1,1,1), hessian = TRUE, y = data$y, x = cbind(1, data$x), method = "BFGS")
linear.MLE$par
?data("infants")
df_s2 <- data.frame(out)
> View(df_s2)
> plot(df_s1)
> out = tab_Q_summary %>%
+   arrange(outcome) %>%
+   mutate(Correct = recode(corr_w1, `-1`="All", `0`="Incorrect", `1`="Correct", `3`="zDinD"),
+          column = paste(outcome, Correct, sep = "_")
+   ) %>%
+   select(-(statistic:corr_w1), -term, -Correct) %>%
+   gather(variable, value, estimate, std.error) %>%
+   mutate(
+     value = format_num(value, 3),
+     value = ifelse(variable == "std.error", paste0("(", value, ")"), value),
+     Congenial = ifelse(is.na(Congenial), "All", as.character(Congenial))
+   ) %>%
+   spread(column, value) %>%
+   select(-variable) %>%
+   select(Category, Congenial, corr_w1_All, cert_w1_Correct, pInitial_cross_Correct, zDiff_Correct, cert_w1_Incorrect, pInitial_cross_Incorrect, zDiff_Incorrect, zDiD_zDinD) %>%
+   mutate(Category = as.character(Category))
>
>
> for(i in nrow(out):2){
+   if(out$Category[i]==out$Category[i-1]) out$Category[i] = ""
+ }
>
> for(i in ((1:(nrow(out)/2))*2-1)){
+   if(out$Congenial[i] == "All"){
+     out$Congenial[i] = "All responses"
+     out$Congenial[i+1] = ""
+   }
+   if(out$Congenial[i] == "Congenial"){
+     out$Congenial[i] = "Correct ans."
+     out$Congenial[i+1] = "is congenial"
+   }
+   if(out$Congenial[i] == "Uncongenial"){
+     out$Congenial[i] = "Incorrect ans."
+     out$Congenial[i+1] = "is congenial"
+   }
+   if(out$Category[i] == "Political knowledge"){
+     out$Category[i] = "Political"
+     out$Category[i+1] = "knowledge"
+   }
+   if(out$Category[i] == "Controversies"){
+     out$Category[i] = "Contro-"
+     out$Category[i+1] = "versies"
+   }
+ }
> View(out)
> View(df_s2)
> out = tab_cross_stabil %>%
+   group_by()  %>%
+   filter(!is.na(Congenial),
+          variable == "pInitial_cross") %>%
+   group_by() %>%
+   left_join(tab_cross_stabil_N %>% filter(
+     variable == "pInitial_cross")
+   ) %>%
+   filter(Date == "March-August 2020") %>%
+   mutate(
+     N = ifelse(is.na(N), 0, N)
+   ) %>%
+   mutate(
+     CI   = paste0("(", format_num(conf.low), ", ", format_num(conf.high), ")"),
+     N = as.character(round(N))
+   ) %>%
+   select(Survey, Category, Congenial, Correct, Certainty=cert_bin_w1, Estimate=estimate, SE=std.error, CI, N)  %>%
+   arrange(Survey, Category, Congenial, Correct, Certainty) %>%
+   mutate(Certainty = recode(Certainty, `0.5`="0.5", `0.55`="[0.51,0.59]", `0.65`="[0.6,0.69]", `0.75`="[0.7,0.79]", `0.85`="[0.8,0.89]", `0.95`="[0.9,0.99]", `1`="1"),
+          Survey = gsub("MTurk, ", "", Survey),
+          Category = ifelse(Congenial == "Political knowledge", "Political knowledge", Category),
+          Congenial = recode(Congenial, `Political knowledge`="Not applicable"))
df_s1 <- data.frame(tab_var$cert_bin_w1, tab_var$estimate)
df_s2 <- data.frame(s2$Certainty, s2$Estimate)
df_s2["2", "s2.Certainty"] <- 0.55
df_s2["3", "s2.Certainty"] <- 0.65
df_s2["4", "s2.Certainty"] <- 0.75
df_s2["5", "s2.Certainty"] <- 0.85
df_s2["6", "s2.Certainty"] <- 0.95
df_s2["9", "s2.Certainty"] <- 0.55
df_s2["10", "s2.Certainty"] <- 0.65
df_s2["11", "s2.Certainty"] <- 0.75
df_s2["12", "s2.Certainty"] <- 0.85
df_s2["13", "s2.Certainty"] <- 0.95
lm_st <- lm(df_s2$s2.Certainty ~ df_s2$s2.Estimate)
lm_s1 <- lm(df_s1$tab_var.cert_bin_w1 ~ df_s1$tab_var.estimate)
abline(lm(df_s2$s2.Certainty ~ df_s2$s2.Estimate))
abline(lm(df_s1$tab_var.cert_bin_w1 ~ df_s1$tab_var.estimate))
plot(lm(df_s2$s2.Certainty ~ df_s2$s2.Estimate))
plot(lm(df_s1$tab_var.cert_bin_w1 ~ df_s1$tab_var.estimate))
summary(lm_st)
lm_s1 <- lm(formula = df_s1$tab_var.cert_bin_w1 ~ df_s1$tab_var.estimate)
lm_s2 <- lm(formula = df_s2$s2.Certainty ~ df_s2$s2.Estimate)
t.test(lm_s1, lm_st, paired = TRUE)
mean(df_s1$tab_var.cert_bin_w1)
mean(df_s2$s2.Certainty)
library(gplots)
plotmeans(tab_var.cert_bin_w1 ~ tab_var.estimate, data = df_s1, frame = FALSE)
plotmeans(s2.Certainty ~ s2.Estimate, data = df_s2, frame= FALSE)
df_s2$s2.Certainty <- as.numeric(df_s2$s2.Certainty)
ggplot(anova(lm_s2, lm_s1))
newvalsforx <- function(x) {
xrng <- seq(min(x), max(x), length.out=100)
function(m) data.frame(x=xrng, y=predict(m, data.frame(x=xrng)))
}
ggplot(d, aes("Expected", "Certainty")) +
geom_point() +
geom_line(data= lm_st, color="red") +
geom_line(data= lm_s1, color="blue")
ggplot(df_s2, aes(lm_s1, lm_s2))
table(df_s1)
abline(lm(lm_s1))
x1 <- df_s1$tab_var.cert_bin_w1
y1 <- df_s1$tab_var.estimate
plot(x1, y1, main = "Respondent Certitude_Incentivized",
xlab = "Certainty", ylab = "Estimate",
pch = 19, frame = FALSE)
abline(lm(y1 ~ x1, data = df_s1), col = "blue")
x2 <- df_s2$s2.Certainty
y2 <- df_s2$s2.Estimate
plot(x2, y2, main = "Respondent Certitude_2-Wave",
xlab = "Certainty", ylab = "Estimate",
pch = 19, frame = FALSE)
abline(lm(y2 ~ x2, data = df_s2), col = "blue")
x <- rnorm(100, 0, 1)
rm(x)
x <- rnorm(100, 0, 1)
?merge
?mean
x <- rnorm(100, 0, 1)
y <- rnorm(100, 0, 1)
plot(x, y)
77001 23 +
y <- c(rep("small", sampe(1, 10:20)), rep("med", sampe(1, 10:20)), rep("large", sampe(1, 10:20)), rep("jumbo", sampe(1, 10:20)))
y <- c(rep("small", sample(1, 10:20)), rep("med", sample(1, 10:20)), rep("large", sample(1, 10:20)), rep("jumbo", sample(1, 10:20)))
?sample
y <- c(rep("small", sample(10:20, 1)), rep("med", sample(10:20, 1)), rep("large", sample(10:20, 1)), rep("jumbo", sample(10:20, 1)))
y
length(y)
table(y)
?mode
mode(y)
getmode <- function(v) {
uniqv <- unique(v)
uniqv[which.max(tabulate(match(v, uniqv)))]
}
getmode(y)
mean(y)
median(y)
x=c(rnorm(18, 0, 1), rnorm(18, 0, 1), rnorm(18, 0, 1), rnorm(18, 0, 1))
test_df <- data.frame(y=c(rep("small", 18), rep("med", 13), rep("large", 14), rep("jumbo", 19)),
test_df <- data.frame(y=c(rep("small", 18), rep("med", 13), rep("large", 14), rep("jumbo", 19)),
x=c(rnorm(18, 0, 1), rnorm(18, 0, 1), rnorm(18, 0, 1), rnorm(18, 0, 1)))
test_df <- data.frame(y=c(rep("small", 18), rep("med", 13), rep("large", 14), rep("jumbo", 19)),
x=c(rnorm(18, 0, 1), rnorm(13, 0, 1), rnorm(14, 0, 1), rnorm(19, 0, 1)))
View(test_df)
library(ggplot2)
ggplot(test_df, aes(x = x, fill = y)) +
geom_histogram(binwidth = .5, alpha =.5, position = "identity")
aggregate(. ~ y, test_df, function(x) c(mean = mean(x), sd = sd(x)))
aggregate(. ~ y, test_df, function(x) c(mean = mean(x), median = median(x), sd = sd(x)))
-1.16+(6.21*1)-(3.82∗2.2) -(1.2*1*2.2)
-1.16+(6.21*1)-(3.82*2.2) -(1.2*1*2.2)
1.16+(6.21*1)-(3.82*0.36) −(1.2*1*0.36)
1.16+(6.21*1)-(3.82*0.36)-(1.2*1*0.36)
-1.16+(6.21*1)-(3.82*2.2) -(1.2*1*2.2)
-1.16+(6.21*1)-(3.82*0.36)-(1.2*1*0.36)
estimate <- -4.238
standard_Error <- 1.848
coefficient <- c('education')
# tscores <- (Estimates-0)/(Standard_Errors)
# p_values <- 2*pt(abs(tscores) , 131-3, lower.tail = F)
model_results <- data.frame(coefficient, estimate, standard_Error)
print(model_results)
CI <-
data.frame("low_CI" = (model_results$estimate - abs(qt((1-.95)/2, df=98))*
model_results$standard_Error),
"estimate" = model_results$estimate,
"high_Ci" = (model_results$estimate + abs(qt((1-.95)/2, df=98))*
model_results$standard_Error))
print(CI)
# Y = 42.39 -2(GDP) -1.303(Dem)-4.238(Edu)
# Y = 42.39 -2(GDP)- 4.238(12.05)
- 4.238*(12.05) #-51.0679
# Y = 42.39 -2(GDP) -51.0679
42.39 -51.0679 # -8.6779
# low
-8.6779 -2*(7403.45) # -14815.58
# high
-8.6779 -2*(43055.11) # -86118.9
-14815.58--86118.9
# load in data
load(url("https://github.com/ASDS-TCD/StatsII_Spring2023/blob/main/datasets/climateSupport.RData?raw=true"))
# relevel sanctions (as per your code)
climateSupport$sanctions <- relevel(factor(climateSupport$sanctions, ordered = F), ref = "5%")
# run model
climate_logit <- glm(choice ~ countries+sanctions, data = climateSupport, family = binomial(link = "logit"))
# create data.frame for prediction
pred <- data.frame(countries = "80 of 192", sanctions = "None")
# predict, type = "response" (0.52)
predict(climate_logit, newdata = pred, type = "response")
# predict, type = "link" (default), with inverse link functions (0.52)
1/(1+exp(-predict(climate_logit, newdata = pred)))
exp(predict(climate_logit, newdata = pred))/(1+exp(predict(climate_logit, newdata = pred)))
# empirically observed mean (0.53)
mean(as.logical(as.numeric(climateSupport$choice)-1)[climateSupport$countries == "80 of 192" & climateSupport$sanctions == "None"])
# extract an example
example <- which(climateSupport$countries == "80 of 192" & climateSupport$sanctions == "None")[1]
# find in model.matrix (0.52)
climate_logit$fitted.values[example]
# extract coefficients (log odds)
coefs <- coef(climate_logit)
coefs
# problem: countries is ordered factor, adding coefs does not match prediction
coefs[1]+(coefs[2]*1)+(coefs[3]*1)+coefs[4]
predict(climate_logit, newdata = pred)
# change to unordered factor and rerun model
climateSupport$countries <- factor(climateSupport$countries, ordered = F)
climate_logit_f <- glm(choice ~ countries+sanctions, data = climateSupport, family = binomial(link = "logit"))
# same prediced value (0.52)
predict(climate_logit_f, newdata = pred, type = "response")
# extract coefficients (log odds)
coefs_f <- coef(climate_logit_f)
# now they're the same as log odds from predict
coefs_f[1] + coefs_f[2] + coefs_f[4]
predict(climate_logit, newdata = pred)
# run your code to calculate predicted probability by hand (0.52)
exp_coefs <- exp(coefs_f[1] + coefs_f[2] + coefs_f[4])
round(exp_coefs/(1+exp_coefs),2)
# load data
load(url("https://github.com/ASDS-TCD/StatsII_Spring2023/blob/main/datasets/climateSupport.RData?raw=true"))
# change baseline category to answer Qs
climateSupport$sanctions <- relevel(factor(climateSupport$sanctions, ordered = F), ref="5%")
str(climateSupport)
climateSupport$countries <- relevel(factor(climateSupport$countries, ordered = F), ref="20 of 192")
str(climateSupport)
# run additive model
climate_logit <- glm(choice~countries+sanctions, data=climateSupport, family = binomial(link = "logit"))
summary(climate_logit)
# (1a)
# option #1: use info from summary() output
# set up hypothesis test yourself & reference chi-sq distribution
pchisq(11783-11568, 5, lower.tail = F)
# option #2: manually run null model & anova
null_logit <- glm(choice~1, data=climateSupport, family = binomial(link = "logit"))
anova(null_logit, climate_logit, test="LRT")
# (2a-b)
texreg(list(climate_logit))
# (2c)
# option #1: predict function
round(1/(1+exp(-predict(climate_logit, newdata = data.frame(countries="80 of 192", sanctions="None"), type="response"))), 2)
# option #2: predicted probability "by hand"
exp_coefs <- exp(coef(climate_logit)[1]+(coef(climate_logit)[2]*1)+(coef(climate_logit)[3]*0)+(coef(climate_logit)[4]*1)+(coef(climate_logit)[5]*0)+(coef(climate_logit)[6]*0))
round(exp_coefs/(1+exp_coefs), 2)
# (2d)
# estimate interactive model
climate_logit_interact <- glm(choice~countries*sanctions, data=climateSupport, family = binomial(link = "logit"))
texreg(list(climate_logit, climate_logit_interact))
# compare to additive model using LRT
anova(climate_logit, climate_logit_interact, test="LRT")
# (2c)
# option #1: predict function
round(predict(climate_logit, newdata = data.frame(countries="80 of 192", sanctions="None"), type="response"))), 2)
# (2c)
# option #1: predict function
round(predict(climate_logit, newdata = data.frame(countries="80 of 192", sanctions="None"), type="response")), 2)
# (2c)
# option #1: predict function
round(predict(climate_logit, newdata = data.frame(countries="80 of 192", sanctions="None"), type="response"), 2)
# option #2: predicted probability "by hand"
exp_coefs <- exp(coef(climate_logit)[1]+(coef(climate_logit)[2]*1)+(coef(climate_logit)[3]*0)+(coef(climate_logit)[4]*1)+(coef(climate_logit)[5]*0)+(coef(climate_logit)[6]*0))
round(exp_coefs/(1+exp_coefs), 2)
# change baseline category to answer Qs
climateSupport$sanctions <- relevel(factor(climateSupport$sanctions, ordered = F), ref="5%")
climateSupport$countries <- relevel(factor(climateSupport$countries, ordered = F), ref="20 of 192")
# run additive model
climate_logit <- glm(choice~countries+sanctions, data=climateSupport, family = binomial(link = "logit"))
summary(climate_logit)
# option #2: manually run null model & anova
null_logit <- glm(choice~1, data=climateSupport, family = binomial(link = "logit"))
anova(null_logit, climate_logit, test="LRT")
# (2a-b)
texreg(list(climate_logit))
lapply(c("texreg"),  pkgTest)
# load data
load(url("https://github.com/ASDS-TCD/StatsII_Spring2023/blob/main/datasets/climateSupport.RData?raw=true"))
# change baseline category to answer Qs
climateSupport$sanctions <- relevel(factor(climateSupport$sanctions, ordered = F), ref="5%")
climateSupport$countries <- relevel(factor(climateSupport$countries, ordered = F), ref="20 of 192")
# run additive model
climate_logit <- glm(choice~countries+sanctions, data=climateSupport, family = binomial(link = "logit"))
summary(climate_logit)
# (1a)
# option #1: use info from summary() output
# set up hypothesis test yourself & reference chi-sq distribution
pchisq(11783-11568, 5, lower.tail = F)
# option #2: manually run null model & anova
null_logit <- glm(choice~1, data=climateSupport, family = binomial(link = "logit"))
anova(null_logit, climate_logit, test="LRT")
# (2a-b)
texreg(list(climate_logit))
# load libraries
pkgTest <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[,  "Package"])]
if (length(new.pkg))
install.packages(new.pkg,  dependencies = TRUE)
sapply(pkg,  require,  character.only = TRUE)
}
lapply(c("texreg"),  pkgTest)
# set wd for current folder
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# load data
load(url("https://github.com/ASDS-TCD/StatsII_Spring2023/blob/main/datasets/climateSupport.RData?raw=true"))
# change baseline category to answer Qs
climateSupport$sanctions <- relevel(factor(climateSupport$sanctions, ordered = F), ref="5%")
climateSupport$countries <- relevel(factor(climateSupport$countries, ordered = F), ref="20 of 192")
# run additive model
climate_logit <- glm(choice~countries+sanctions, data=climateSupport, family = binomial(link = "logit"))
summary(climate_logit)
# (1a)
# option #1: use info from summary() output
# set up hypothesis test yourself & reference chi-sq distribution
pchisq(11783-11568, 5, lower.tail = F)
# option #2: manually run null model & anova
null_logit <- glm(choice~1, data=climateSupport, family = binomial(link = "logit"))
anova(null_logit, climate_logit, test="LRT")
# (2a-b)
texreg(list(climate_logit))
# (2c)
# option #1: predict function
round(predict(climate_logit, newdata = data.frame(countries="80 of 192", sanctions="None"), type="response"), 2)
# option #2: predicted probability "by hand"
exp_coefs <- exp(coef(climate_logit)[1]+(coef(climate_logit)[2]*1)+(coef(climate_logit)[3]*0)+(coef(climate_logit)[4]*1)+(coef(climate_logit)[5]*0)+(coef(climate_logit)[6]*0))
round(exp_coefs/(1+exp_coefs), 2)
# (2d)
# estimate interactive model
climate_logit_interact <- glm(choice~countries*sanctions, data=climateSupport, family = binomial(link = "logit"))
texreg(list(climate_logit, climate_logit_interact))
# (2d)
# estimate interactive model
climate_logit_interact <- glm(choice~countries*sanctions, data=climateSupport, family = binomial(link = "logit"))
texreg(list(climate_logit, climate_logit_interact))
# compare to additive model using LRT
anova(climate_logit, climate_logit_interact, test="LRT")
# remove objects
rm(list=ls())
# detach all libraries
detachAllPackages <- function() {
basic.packages <- c("package:stats", "package:graphics", "package:grDevices", "package:utils", "package:datasets", "package:methods", "package:base")
package.list <- search()[ifelse(unlist(gregexpr("package:", search()))==1, TRUE, FALSE)]
package.list <- setdiff(package.list, basic.packages)
if (length(package.list)>0)  for (package in package.list) detach(package,  character.only=TRUE)
}
detachAllPackages()
# load libraries
pkgTest <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[,  "Package"])]
if (length(new.pkg))
install.packages(new.pkg,  dependencies = TRUE)
sapply(pkg,  require,  character.only = TRUE)
}
lapply(c("texreg"),  pkgTest)
# set wd for current folder
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# load data
load(url("https://github.com/ASDS-TCD/StatsII_Spring2023/blob/main/datasets/climateSupport.RData?raw=true"))
# change baseline category to answer Qs
climateSupport$sanctions <- relevel(factor(climateSupport$sanctions, ordered = F), ref="5%")
climateSupport$countries <- relevel(factor(climateSupport$countries, ordered = F), ref="20 of 192")
# run additive model
climate_logit <- glm(choice~countries+sanctions, data=climateSupport, family = binomial(link = "logit"))
summary(climate_logit)
# remove objects
rm(list=ls())
# detach all libraries
detachAllPackages <- function() {
basic.packages <- c("package:stats", "package:graphics", "package:grDevices", "package:utils", "package:datasets", "package:methods", "package:base")
package.list <- search()[ifelse(unlist(gregexpr("package:", search()))==1, TRUE, FALSE)]
package.list <- setdiff(package.list, basic.packages)
if (length(package.list)>0)  for (package in package.list) detach(package,  character.only=TRUE)
}
detachAllPackages()
# load libraries
pkgTest <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[,  "Package"])]
if (length(new.pkg))
install.packages(new.pkg,  dependencies = TRUE)
sapply(pkg,  require,  character.only = TRUE)
}
lapply(c("texreg"),  pkgTest)
# set wd for current folder
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# load data
load(url("https://github.com/ASDS-TCD/StatsII_Spring2024/blob/main/datasets/climateSupport.RData?raw=true"))
View(climateSupport)
# run additive model
climate_logit <- glm(choice~countries+sanctions, data=climateSupport, family = binomial(link = "logit"))
summary(climate_logit)
